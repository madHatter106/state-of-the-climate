{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from IPython.core.display import HTML, display\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width: 90%}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container {width: 90%}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_secs2dt(sec):\n",
    "    \"\"\"\n",
    "    Converts seconds to python datetime object.\n",
    "    :param sec \n",
    "    :return: datetime object\n",
    "    \"\"\"\n",
    "    zd00 = datetime(2000, 1, 1)\n",
    "    zd70 = datetime(1970, 1, 1)\n",
    "    offset = (zd00 - zd70).total_seconds()\n",
    "    z = datetime.utcfromtimestamp(sec + offset)\n",
    "    return z\n",
    "\n",
    "\n",
    "def get_doy(secs):\n",
    "    \"\"\"\n",
    "    Converts seconds to fractional day of year.\n",
    "    :param secs\n",
    "    :return: fractional day of year \n",
    "    \"\"\"\n",
    "    z = convert_secs2dt(secs)\n",
    "    y = z.year\n",
    "    return (secs + (datetime(2000, 1, 1) - datetime(y, 1, 1)).total_seconds()) / 86400\n",
    "\n",
    "\n",
    "def load_format_data(filepath, minimal=True, columns=None, quantity='chl_a'):\n",
    "    \"\"\"\n",
    "    Loads chlorophyll data into a pandas dataframe,\n",
    "    formats time entries, and creates a datetime index.\n",
    "    :param filepath: string or pathlib object  \n",
    "    :param minimal: if True returns only chl_a_mean; drops the rest.\n",
    "    :return: pandas datetime indexed dataframe\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = ['time', 'nbins', 'mean', 'median', 'stdv']\n",
    "    \n",
    "    df = pd.read_csv(filepath, delim_whitespace=True, names=columns)\n",
    "    df['datetime'] = df.time.apply(convert_secs2dt)\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    if minimal:\n",
    "        df = df[['mean']]\n",
    "    df.rename(columns={'mean': '%s_mean' % quantity}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_phyto_C_stats(df_):\n",
    "    bbp_443_ = df_.bbp_443_giop_adj_mean.values.reshape(1,-1)\n",
    "    phyto_c_trace_ = intercept + bbp_443_ * slope\n",
    "    phyto_c_mean = phyto_c_trace_.mean(axis=0)\n",
    "    phyto_c_hpd = pm.hpd(phyto_c_trace_)\n",
    "    df_.insert(loc=1, column='phyto_C_2.5%', value=phyto_c_hpd[:, 0])\n",
    "    df_.insert(loc=2, column='phyto_C_97.5%', value=phyto_c_hpd[:, 1])\n",
    "    df_.insert(loc=2, column='phyto_C_mean', value=phyto_c_mean)\n",
    "    return df_\n",
    "\n",
    "def get_monthly_means(df, **kwargs):\n",
    "    \"\"\"\n",
    "    Groups data by month and compute annual cycle based on monthly means.\n",
    "    :param df: \n",
    "        datetime indexed pandas dataframe\n",
    "    :param kwargs:\n",
    "        year_start (optional): string, slice start\n",
    "        year_end (optional): string, slice end\n",
    "    :return: \n",
    "        month-indexed pandas dataframe with monthly means\n",
    "    \"\"\"\n",
    "    year_start = kwargs.pop('year_start', df.index.year[0])\n",
    "    year_end = kwargs.pop('year_end', df.index.year[-1])\n",
    "    return df.loc[str(year_start): str(year_end)].groupby(lambda x: x.month).aggregate('mean')\n",
    "\n",
    "\n",
    "def get_anomaly(df, df_ann_cycle, name='chl_a_mean', anomaly_name='anomaly'):\n",
    "    \"\"\"\n",
    "    Computes annomaly by removing monthly mean for a given month\n",
    "    :param df:\n",
    "        pandas dataframe with [name] parameter column\n",
    "    :param df_ann_cycle:\n",
    "        pandas dataframe of length 12 containing monthly means\n",
    "    :param name:\n",
    "        str, label of quantity to get anomaly from\n",
    "    :return:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    for month in df_ann_cycle.index:\n",
    "        idx = df.index.month == month\n",
    "        df.loc[idx, anomaly_name] = df.loc[idx, name] - df_ann_cycle.loc[month, name]\n",
    "\n",
    "\n",
    "def test(datadir):\n",
    "    testfile = datadir / 'ar2018.0m_AtlN55_chlor_a.txt'\n",
    "    df_test = load_format_data(testfile, minimal=False)\n",
    "    t0 = df_test.time[0]    \n",
    "    z0 = convert_secs2dt(t0)\n",
    "    zstr0 = z0.strftime('%Y%j%H%M%S')\n",
    "    try:\n",
    "        assert zstr0 + '000' == str(2002197194740000)\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        print(zstr0)\n",
    "    assert z0.year == 2002\n",
    "    doy0 = get_doy(t0)\n",
    "    assert doy0 == 196.82476851851851\n",
    "    tl = df_test.tail(1).time.values\n",
    "    zl = convert_secs2dt(tl)\n",
    "    zstrl = zl.strftime('%Y%j%H%M%S')\n",
    "    assert zstrl + '000' == str(2016321013320000)\n",
    "    assert zl.year == 2016\n",
    "    doyl = get_doy(tl)\n",
    "    assert doyl == 320.06481481481484\n",
    "    print(\"all tests passed\")\n",
    "\n",
    "def get_sensor(row, prod):\n",
    "    if np.isfinite(row[f'adj_{prod}_s'] * row[f'adj_{prod}_a']):\n",
    "        return 'both'\n",
    "    else:\n",
    "        if np.isfinite(row[f'adj_{prod}_s']):\n",
    "            return 'swf'\n",
    "        else:\n",
    "            return 'aqua'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=pathlib.Path('/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/pso_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pklJar/pooled_params.pkl', 'rb') as fb:\n",
    "    pooled_params_dict = pickle.load(fb)\n",
    "slope = pooled_params_dict['slope']\n",
    "slope = slope.reshape(-1, 1)\n",
    "intercept = pooled_params_dict['intercept']\n",
    "intercept = intercept.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/pso_test/st134m_eqpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/pso_test/at168m_eqpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/pso_test/st134m_nhpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/pso_test/st134m_shpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/pso_test/at168m_shpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/pso_test/at168m_nhpso_bbp_443_giop.txt\n"
     ]
    }
   ],
   "source": [
    "for file in path.glob('*.txt'):\n",
    "    print(file.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_regionals(path_, **kwargs):\n",
    "    regions = kwargs.pop('regions', ['eqpso', 'nhpso', 'shpso'])\n",
    "    prods = kwargs.pop('prods', ['chlor_a', 'bbp_443_giop'])\n",
    "    sensors = kwargs.pop('sensors', ['aqua' ,'swf', 'swf_aqua'])\n",
    "    dict_ = {reg: {prod: dict.fromkeys(sensors) \n",
    "               for prod in prods} \n",
    "         for reg in regions}\n",
    "    for file in path_.glob('*.txt'):\n",
    "    \n",
    "        key_reg, key_prod = None, None\n",
    "        for reg in regions:\n",
    "            if reg in file.name:\n",
    "                key_reg = reg\n",
    "                break\n",
    "        for prod in prods:\n",
    "            if prod in file.name:\n",
    "                key_prod=prod\n",
    "                break\n",
    "        sensor = 'aqua' if 'ar' in file.name or 'at' in file.name else 'swf'\n",
    "        df_ = load_format_data(file, quantity=key_prod)\n",
    "        df_.rename({col: f'{sensor[0]}_{col}' for col in df_.columns},\n",
    "                   axis=1, inplace=True)\n",
    "        if sensor == 'swf':\n",
    "            df_ = df_.loc[:'2007', :]\n",
    "        dict_[key_reg][key_prod][sensor] = df_\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['eqpso', 'nhpso', 'shpso']\n",
    "prods=['bbp_443_giop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_df = load_regionals(path, prods=['bbp_443_giop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate(dct_df_, **kwargs):\n",
    "\n",
    "    regions = kwargs.pop('regions', ['eqpso', 'nhpso', 'shpso'])\n",
    "    prods = kwargs.pop('prods', ['chlor_a', 'bbp_443_giop'])\n",
    "    for reg in regions:\n",
    "        for prod in prods:\n",
    "            df_aqua = dct_df_[reg][prod]['aqua']\n",
    "            df_swf = dct_df_[reg][prod]['swf']\n",
    "            df_all = pd.concat((df_aqua.resample('MS', loffset=pd.Timedelta(14, 'd')).first(),\n",
    "                                       df_swf.resample('MS', loffset=pd.Timedelta(14, 'd')).first()),\n",
    "                                      axis=1)\n",
    "            df_both=df_all.dropna().copy()\n",
    "            df_both.insert(0, f'{prod}_mean', df_both[[f's_{prod}_mean',\n",
    "                                                       f'a_{prod}_mean']\n",
    "                                                     ].mean(axis=1))\n",
    "            df_both.insert(1, f'aqua-{prod}_mean',\n",
    "                           df_both[f'a_{prod}_mean']- df_both[f'{prod}_mean'])\n",
    "            df_both.insert(1, f'{prod}_mean-swf',\n",
    "                           df_both[f'{prod}_mean'] - df_both[f's_{prod}_mean'])\n",
    "            df_all[f'adj_{prod}_s'] = df_all[f's_{prod}_mean'] + df_both[f'{prod}_mean-swf'].mean()\n",
    "            df_all[f'adj_{prod}_a'] = df_all[f'a_{prod}_mean'] + df_both[f'aqua-{prod}_mean'].mean()\n",
    "            df_all[f'{prod}_adj_mean'] = df_all[[f'adj_{prod}_s', f'adj_{prod}_a']].mean(axis=1)\n",
    "            df_all_sub = df_all[[f'{prod}_adj_mean']].copy()\n",
    "            if 'bbp' in prod:\n",
    "                df_all_sub = compute_phyto_C_stats(df_all_sub)\n",
    "            prod_ = 'phyto_C' if 'bbp' in prod else f'{prod}_adj'\n",
    "            prod_ann_cycle = get_monthly_means(df_all_sub[[f'{prod_}_mean']],\n",
    "                                               year_start=2003, year_end=2011)\n",
    "            get_anomaly(df_all_sub, prod_ann_cycle, name=f'{prod_}_mean',\n",
    "                       anomaly_name=f'{prod_}_anomaly')\n",
    "            df_all_sub['sensor'] = df_all.apply(get_sensor, args=(prod,), axis=1)\n",
    "            dct_df_[reg][prod].update(dict(df_all=df_all_sub))\n",
    "    return dct_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_df = consolidate(dct_df, prods=['bbp_443_giop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbp_443_giop_adj_mean</th>\n",
       "      <th>phyto_C_2.5%</th>\n",
       "      <th>phyto_C_mean</th>\n",
       "      <th>phyto_C_97.5%</th>\n",
       "      <th>phyto_C_anomaly</th>\n",
       "      <th>sensor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-11-15</th>\n",
       "      <td>0.002056</td>\n",
       "      <td>22.581171</td>\n",
       "      <td>24.636688</td>\n",
       "      <td>26.757878</td>\n",
       "      <td>0.351013</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-12-15</th>\n",
       "      <td>0.001952</td>\n",
       "      <td>21.562679</td>\n",
       "      <td>23.416629</td>\n",
       "      <td>25.457866</td>\n",
       "      <td>-0.148330</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-15</th>\n",
       "      <td>0.001897</td>\n",
       "      <td>21.003003</td>\n",
       "      <td>22.765257</td>\n",
       "      <td>24.761081</td>\n",
       "      <td>-0.102792</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-02-15</th>\n",
       "      <td>0.001886</td>\n",
       "      <td>20.887363</td>\n",
       "      <td>22.639052</td>\n",
       "      <td>24.620916</td>\n",
       "      <td>-0.255566</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-03-15</th>\n",
       "      <td>0.001942</td>\n",
       "      <td>21.455046</td>\n",
       "      <td>23.301481</td>\n",
       "      <td>25.323546</td>\n",
       "      <td>0.044388</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bbp_443_giop_adj_mean  phyto_C_2.5%  phyto_C_mean  phyto_C_97.5%  \\\n",
       "datetime                                                                       \n",
       "1997-11-15               0.002056     22.581171     24.636688      26.757878   \n",
       "1997-12-15               0.001952     21.562679     23.416629      25.457866   \n",
       "1998-01-15               0.001897     21.003003     22.765257      24.761081   \n",
       "1998-02-15               0.001886     20.887363     22.639052      24.620916   \n",
       "1998-03-15               0.001942     21.455046     23.301481      25.323546   \n",
       "\n",
       "            phyto_C_anomaly sensor  \n",
       "datetime                            \n",
       "1997-11-15         0.351013    swf  \n",
       "1997-12-15        -0.148330    swf  \n",
       "1998-01-15        -0.102792    swf  \n",
       "1998-02-15        -0.255566    swf  \n",
       "1998-03-15         0.044388    swf  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = 'eqpso'\n",
    "dct_df[reg]['bbp_443_giop']['df_all'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbp_443_giop_adj_mean</th>\n",
       "      <th>phyto_C_2.5%</th>\n",
       "      <th>phyto_C_mean</th>\n",
       "      <th>phyto_C_97.5%</th>\n",
       "      <th>phyto_C_anomaly</th>\n",
       "      <th>sensor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-08-15</th>\n",
       "      <td>0.001967</td>\n",
       "      <td>21.674066</td>\n",
       "      <td>23.594234</td>\n",
       "      <td>25.610215</td>\n",
       "      <td>0.650477</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-15</th>\n",
       "      <td>0.001964</td>\n",
       "      <td>21.688976</td>\n",
       "      <td>23.560242</td>\n",
       "      <td>25.619215</td>\n",
       "      <td>-0.003653</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-10-15</th>\n",
       "      <td>0.002034</td>\n",
       "      <td>22.355823</td>\n",
       "      <td>24.374692</td>\n",
       "      <td>26.468022</td>\n",
       "      <td>0.070558</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-11-15</th>\n",
       "      <td>0.002008</td>\n",
       "      <td>22.165679</td>\n",
       "      <td>24.070648</td>\n",
       "      <td>26.207698</td>\n",
       "      <td>-0.215027</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-15</th>\n",
       "      <td>0.001968</td>\n",
       "      <td>21.687035</td>\n",
       "      <td>23.608466</td>\n",
       "      <td>25.627197</td>\n",
       "      <td>0.043506</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bbp_443_giop_adj_mean  phyto_C_2.5%  phyto_C_mean  phyto_C_97.5%  \\\n",
       "datetime                                                                       \n",
       "2007-08-15               0.001967     21.674066     23.594234      25.610215   \n",
       "2007-09-15               0.001964     21.688976     23.560242      25.619215   \n",
       "2007-10-15               0.002034     22.355823     24.374692      26.468022   \n",
       "2007-11-15               0.002008     22.165679     24.070648      26.207698   \n",
       "2007-12-15               0.001968     21.687035     23.608466      25.627197   \n",
       "\n",
       "            phyto_C_anomaly sensor  \n",
       "datetime                            \n",
       "2007-08-15         0.650477   both  \n",
       "2007-09-15        -0.003653   both  \n",
       "2007-10-15         0.070558   both  \n",
       "2007-11-15        -0.215027   both  \n",
       "2007-12-15         0.043506   both  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_df[reg]['bbp_443_giop']['df_all'].loc[:'2007'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbp_443_giop_adj_mean</th>\n",
       "      <th>phyto_C_2.5%</th>\n",
       "      <th>phyto_C_mean</th>\n",
       "      <th>phyto_C_97.5%</th>\n",
       "      <th>phyto_C_anomaly</th>\n",
       "      <th>sensor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-15</th>\n",
       "      <td>0.001881</td>\n",
       "      <td>20.831817</td>\n",
       "      <td>22.580714</td>\n",
       "      <td>24.552605</td>\n",
       "      <td>-0.287336</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-15</th>\n",
       "      <td>0.001914</td>\n",
       "      <td>21.185311</td>\n",
       "      <td>22.972619</td>\n",
       "      <td>24.984008</td>\n",
       "      <td>0.078001</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-15</th>\n",
       "      <td>0.001921</td>\n",
       "      <td>21.255599</td>\n",
       "      <td>23.054129</td>\n",
       "      <td>25.069227</td>\n",
       "      <td>-0.202964</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-15</th>\n",
       "      <td>0.001934</td>\n",
       "      <td>21.363554</td>\n",
       "      <td>23.207739</td>\n",
       "      <td>25.216820</td>\n",
       "      <td>-0.093886</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-15</th>\n",
       "      <td>0.001876</td>\n",
       "      <td>20.778901</td>\n",
       "      <td>22.524139</td>\n",
       "      <td>24.490607</td>\n",
       "      <td>-0.291760</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bbp_443_giop_adj_mean  phyto_C_2.5%  phyto_C_mean  phyto_C_97.5%  \\\n",
       "datetime                                                                       \n",
       "2008-01-15               0.001881     20.831817     22.580714      24.552605   \n",
       "2008-02-15               0.001914     21.185311     22.972619      24.984008   \n",
       "2008-03-15               0.001921     21.255599     23.054129      25.069227   \n",
       "2008-04-15               0.001934     21.363554     23.207739      25.216820   \n",
       "2008-05-15               0.001876     20.778901     22.524139      24.490607   \n",
       "\n",
       "            phyto_C_anomaly sensor  \n",
       "datetime                            \n",
       "2008-01-15        -0.287336   aqua  \n",
       "2008-02-15         0.078001   aqua  \n",
       "2008-03-15        -0.202964   aqua  \n",
       "2008-04-15        -0.093886   aqua  \n",
       "2008-05-15        -0.291760   aqua  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_df[reg]['bbp_443_giop']['df_all'].loc['2008':].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg in regions:\n",
    "    for prod in prods:\n",
    "        df_name = f'df_{reg}_{prod}_test_data_consolidated'\n",
    "        dct_df[reg][prod]['df_all'].to_pickle(f'../PklJar/{df_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../PklJar/dct_df_test.pkl', 'wb') as f:\n",
    "    pickle.dump(dct_df, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "n = np.arange(10)\n",
    "p = np.linspace(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame([[ni, pi] for ni in n for pi in p], columns=['n', 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ = d.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_learning]",
   "language": "python",
   "name": "conda-env-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
