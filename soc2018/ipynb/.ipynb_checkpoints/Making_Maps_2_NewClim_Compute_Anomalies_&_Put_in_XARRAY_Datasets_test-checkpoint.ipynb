{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous notebook I prepared and pickled dictionaries keyed by month and containing file paths for sst/chl monthlies/climatology for aqua and chl monthlies for viirs. Here I \n",
    "- load all files, \n",
    "- compute aqua chl anomalies, \n",
    "- sst anomalies, and viirs chl anomalies,\n",
    "- stick these in xarray [dataarrays](http://xarray.pydata.org/en/stable/data-structures.html#dataarray),\n",
    "- put all anomaly dataarrays in a xarray [dataset](http://xarray.pydata.org/en/stable/data-structures.html#dataset),\n",
    "- save it to netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime as DT\n",
    "\n",
    "from netCDF4 import Dataset as ds\n",
    "import numpy as np\n",
    "from numpy import testing as npt\n",
    "from tqdm import tqdm_notebook\n",
    "import xarray as xr\n",
    "from IPython.core.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataarray(data_dict, prod='chlor_a', **kwargs):\n",
    "    \"\"\"\"\"\"\n",
    "    units = kwargs.pop('units', None)\n",
    "    name = kwargs.pop('name', prod)\n",
    "    coords_ = kwargs.pop('coords', ['time', 'lat', 'lon'])\n",
    "    xr_data = xr.DataArray(data_dict[prod], \n",
    "                           coords=[data_dict[val] for val in coords_],\n",
    "                           dims = [key for key in coords_])\n",
    "    if units:\n",
    "        xr_data.attrs['units'] = units\n",
    "    xr_data.name = name\n",
    "    return xr_data\n",
    "\n",
    "\n",
    "def make_dataset(*data_array_list):\n",
    "    \"\"\"list of xarray dataarrays. These need the name attribute set.\"\"\"\n",
    "    xr_ds = xr.Dataset({data_array.name: data_array for data_array in data_array_list \n",
    "                        })\n",
    "    return xr_ds\n",
    "\n",
    " \n",
    "def make_anom_sign(prod1_an_avg, prod2_an_avg):\n",
    "    \"\"\"\n",
    "    returs sign relation array\n",
    "    0: both are neg\n",
    "    1: neg chl, pos sst\n",
    "    2: pos chl, neg sst\n",
    "    3: pos chl, pos sst\n",
    "    \"\"\"\n",
    "    prod1_anom_sign = np.ma.where(prod1_an_avg<0, 0, 2)\n",
    "    prod2_anom_sign = np.ma.where(prod2_an_avg<0, 0, 1)\n",
    "    return prod1_anom_sign.round().astype('int') + prod2_anom_sign.round().astype('int')\n",
    "\n",
    "    \n",
    "def get_monthly_anoms(mc_dict, mo_dict, prod='chlor_a', perc_anom=False,\n",
    "                      verbose=False, **kwargs):\n",
    "    \"\"\"Make anomalies from monthlies and climatology\"\"\"\n",
    "    # process kwargs\n",
    "    lat_dim = kwargs.pop('lat_dim', 2160)\n",
    "    lon_dim = kwargs.pop('lon_dim', 4320)\n",
    "    time_dim = kwargs.pop('time_dim', 12)\n",
    "    year = kwargs.pop('year', 2016)\n",
    "    scale_slp = kwargs.pop('scale_slope', 1)\n",
    "    scale_itc = kwargs.pop('scale_intercept', 0)\n",
    "\n",
    "    # setup data structures\n",
    "    anom_array = np.ma.zeros((time_dim, lat_dim, lon_dim))\n",
    "    months = mo_dict.keys()\n",
    "    for i, month in enumerate(tqdm_notebook(months)):\n",
    "        with ds(mo_dict[month]) as mo_ds:\n",
    "            try:\n",
    "                mo_prod = mo_ds[prod][:]\n",
    "            except IndexError:\n",
    "                print(f'missing {prod} in MO for month of {month}')\n",
    "            lat_mo = mo_ds['lat'][:]\n",
    "            lon_mo = mo_ds['lon'][:]\n",
    "        with ds(mc_dict[month]) as mc_ds:\n",
    "            mc_prod = mc_ds[prod][:]\n",
    "            lat_mc = mc_ds['lat'][:]\n",
    "            lon_mc = mc_ds['lon'][:]\n",
    "        if verbose:\n",
    "            print(f'processing {month}...')\n",
    "            print(f'processing mc: {mc_dict[month]}')\n",
    "            print(f'processing mo: {mo_dict[month]}')\n",
    "        # check lat/lon correspondence\n",
    "        npt.assert_array_equal(lat_mo, lat_mc)\n",
    "        npt.assert_array_equal(lon_mo, lon_mc)\n",
    "        # compute anomalies\n",
    "        anom_array[i] = (mo_prod - mc_prod) * scale_slp\n",
    "        if perc_anom:\n",
    "            anom_array[i] = anom_array[i] * 100 / ((mc_prod * scale_slp) + scale_itc)\n",
    "    # convert time data into array of datetime objects\n",
    "    time_array = np.array([DT.strptime('%s-%d' %(month, year), '%b-%Y') for month in months],\n",
    "                          dtype='datetime64[ns]')\n",
    "    return {'%s_anom' % prod: anom_array,\n",
    "            'lat': lat_mc, 'lon': lon_mc,\n",
    "            'time': time_array,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width: 90% !important}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container {width: 90% !important}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Load serialized dictionary from previous notebook</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../PklJar/smi_dicts_2018_9km.pkl', 'rb') as fp:\n",
    "    files_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jan': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20180012018031.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Feb': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20180322018059.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Mar': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20180602018090.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Apr': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20180912018120.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'May': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20181212018151.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Jun': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20181522018181.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Jul': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20181822018212.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Aug': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20182132018243.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Sep': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20182442018273.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Oct': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20182742018304.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Nov': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20183052018334.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Dec': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20183352018365.L3m_MO_IOP_bbp_443_giop_9km.nc')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dict['aqua_bbp_mo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Compute anomalies and store</u>\n",
    "\n",
    "Anomaly data is stored in dictionaries of dictionaries with sensor (aqua/viirs) as higher key, and \n",
    " - '[product]_anom', \n",
    " - 'lat', \n",
    " - 'lon', \n",
    " - 'time' \n",
    " \n",
    " as lower keys.</u> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jan': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20180012018031.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Feb': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20180322018059.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Mar': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20180602018090.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Apr': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20180912018120.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'May': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20181212018151.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Jun': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20181522018181.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Jul': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20181822018212.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Aug': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20182132018243.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Sep': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20182442018273.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Oct': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20182742018304.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Nov': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20183052018334.L3m_MO_IOP_bbp_443_giop_9km.nc'),\n",
       " 'Dec': PosixPath('/accounts/ekarakoy/DATA/SOC/SOC_2018/Aqua_MO/bbp_443_giop/A20183352018365.L3m_MO_IOP_bbp_443_giop_9km.nc')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dict['aqua_bbp_mo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./pklJar/pooled_params.pkl', 'rb') as fb:\n",
    "    pooled_params_dict = pickle.load(fb)\n",
    "b2C_slp_mean = pooled_params_dict['slope'].mean()\n",
    "b2C_itc_mean = pooled_params_dict['intercept'].mean()\n",
    "del pooled_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39379dd298c64b17904098526a9727b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "months_available = len(files_dict['aqua_bbp_mo'].keys())\n",
    "bbp_anom_dict = get_monthly_anoms(files_dict['aqua_bbp_mc'],\n",
    "                                  mo_dict=files_dict['aqua_bbp_mo'],\n",
    "                                  year=current_year, prod='bbp_443_giop',\n",
    "                                  time_dim=months_available, perc_anom=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfa113fa8814597bd89b9c83be407d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "months_available = len(files_dict['aqua_bbp_mo'].keys())\n",
    "phytoC_anom_dict = get_monthly_anoms(files_dict['aqua_bbp_mc'],\n",
    "                                  mo_dict=files_dict['aqua_bbp_mo'],\n",
    "                                  year=current_year, prod='bbp_443_giop',\n",
    "                                  time_dim=months_available, perc_anom=True,\n",
    "                                  scale_slope=b2C_slp_mean, scale_intercept=b2C_itc_mean)\n",
    "phytoC_anom_dict['phytoC_anom'] = phytoC_anom_dict.pop('bbp_443_giop_anom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4a16cbeeeb40d08647e9814258bfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "months_available = len(files_dict['aqua_chl_mo'].keys())\n",
    "chl_anom_dict = get_monthly_anoms(files_dict['aqua_chl_mc'],\n",
    "                                  mo_dict=files_dict['aqua_chl_mo'],\n",
    "                                  year=current_year,\n",
    "                                  time_dim=months_available, perc_anom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f2de73bb314a238a6e2773b52f7522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "months_available = len(files_dict['aqua_sst_mo'].keys())\n",
    "sst_anom_dict = get_monthly_anoms(files_dict['aqua_sst_mc'],\n",
    "                                  mo_dict=files_dict['aqua_sst_mo'],\n",
    "                                  prod='sst', year=current_year,\n",
    "                                 time_dim=months_available, perc_anom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Consistency tests</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npt.assert_array_equal(sst_anom_dict['time'], chl_anom_dict['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npt.assert_array_equal(sst_anom_dict['time'], bbp_anom_dict['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npt.assert_array_equal(sst_anom_dict['lat'], chl_anom_dict['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npt.assert_array_equal(sst_anom_dict['lon'], bbp_anom_dict['lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Stick anomalies in xarray [dataarrays](http://xarray.pydata.org/en/stable/data-structures.html#dataarray) and dataarrays into an xarray [dataset](http://xarray.pydata.org/en/stable/data-structures.html#dataset)</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xr_aqua_chl_anom = make_dataarray(chl_anom_dict, prod='chlor_a_anom', units='%')\n",
    "xr_aqua_bbp_anom = make_dataarray(bbp_anom_dict, prod='bbp_443_giop_anom', units='%')\n",
    "xr_aqua_phyC_anom = make_dataarray(phytoC_anom_dict, prod='phytoC_anom', units='%')\n",
    "xr_sst_anom = make_dataarray(sst_anom_dict, prod='sst_anom', units='deg C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_anom = xr.Dataset({'aqua_chl_anom': xr_aqua_chl_anom,\n",
    "                      'aqua_phyC_anom': xr_aqua_phyC_anom,\n",
    "                      'aqua_bbp_443_anom': xr_aqua_bbp_anom,\n",
    "                      'aqua_sst_anom': xr_sst_anom,\n",
    "                     })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute yearly mean and add into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_anom['time_avg_aqua_chl_anom'] = ds_anom['aqua_chl_anom'].mean(axis=0)\n",
    "ds_anom['time_avg_aqua_phyC_anom'] = ds_anom['aqua_phyC_anom'].mean(axis=0)\n",
    "ds_anom['time_avg_aqua_bbp_443_anom'] = ds_anom['aqua_bbp_443_anom'].mean(axis=0)\n",
    "ds_anom['time_avg_sst_anom'] = ds_anom.aqua_sst_anom.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute SST/CHL sign relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aqua_chl_anom_mean = chl_anom_dict['chlor_a_anom'].mean(axis=0)\n",
    "aqua_phyC_anom_mean = phytoC_anom_dict['phytoC_anom'].mean(axis=0)\n",
    "aqua_sst_anom_mean = sst_anom_dict['sst_anom'].mean(axis=0)\n",
    "aqua_bbp_anom_mean = bbp_anom_dict['bbp_443_giop_anom'].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aqua_chl_sst_anom_sign = make_anom_sign(aqua_chl_anom_mean, aqua_sst_anom_mean)\n",
    "aqua_bbp_sst_anom_sign = make_anom_sign(aqua_bbp_anom_mean, aqua_sst_anom_mean)\n",
    "aqua_chl_bbp_anom_sign = make_anom_sign(aqua_chl_anom_mean, aqua_bbp_anom_mean)\n",
    "aqua_phyC_sst_anom_sign = make_anom_sign(aqua_phyC_anom_mean, aqua_sst_anom_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aqua_chl_sst_anom_dict = dict(aqua_chl_sst_anom_sign=aqua_chl_sst_anom_sign,\n",
    "                              lat=chl_anom_dict['lat'], lon=chl_anom_dict['lon'])\n",
    "aqua_bbp_sst_anom_dict = dict(aqua_bbp_sst_anom_sign=aqua_bbp_sst_anom_sign,\n",
    "                              lat=bbp_anom_dict['lat'], lon=bbp_anom_dict['lon'])\n",
    "aqua_chl_bbp_anom_dict = dict(aqua_chl_bbp_anom_sign=aqua_chl_bbp_anom_sign,\n",
    "                              lat=chl_anom_dict['lat'], lon=chl_anom_dict['lon'])\n",
    "aqua_phyC_sst_anom_dict = dict(aqua_phyC_sst_anom_sign=aqua_phyC_sst_anom_sign,\n",
    "                              lat=phytoC_anom_dict['lat'], lon=phytoC_anom_dict['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xr_aqua_chl_sst_anom_sign = make_dataarray(aqua_chl_sst_anom_dict,\n",
    "                                           prod='aqua_chl_sst_anom_sign',\n",
    "                                           coords=['lat', 'lon'])\n",
    "xr_aqua_bbp_sst_anom_sign = make_dataarray(aqua_bbp_sst_anom_dict,\n",
    "                                           prod='aqua_bbp_sst_anom_sign',\n",
    "                                           coords=['lat', 'lon'])\n",
    "xr_aqua_chl_bbp_anom_sign = make_dataarray(aqua_chl_bbp_anom_dict,\n",
    "                                           prod='aqua_chl_bbp_anom_sign',\n",
    "                                           coords=['lat', 'lon'])\n",
    "xr_aqua_phyC_sst_anom_sign = make_dataarray(aqua_phyC_sst_anom_dict,\n",
    "                                            prod='aqua_phyC_sst_anom_sign',\n",
    "                                            coords=['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nviirs_chl_sst_anom_dict = dict(viirs_chl_sst_anom_sign=viirs_chl_sst_anom_sign,\\n                         lat=chl_anom_dict['viirs']['lat'], lon=chl_anom_dict['viirs']['lon'])\\nxr_viirs_chl_sst_anom_sign = make_dataarray(viirs_chl_sst_anom_dict, prod='viirs_chl_sst_anom_sign',\\n                                     coords=['lat', 'lon'])\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "viirs_chl_sst_anom_dict = dict(viirs_chl_sst_anom_sign=viirs_chl_sst_anom_sign,\n",
    "                         lat=chl_anom_dict['viirs']['lat'], lon=chl_anom_dict['viirs']['lon'])\n",
    "xr_viirs_chl_sst_anom_sign = make_dataarray(viirs_chl_sst_anom_dict, prod='viirs_chl_sst_anom_sign',\n",
    "                                     coords=['lat', 'lon'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_anom['aqua_chl_sst_anom_sign'] = xr_aqua_chl_sst_anom_sign\n",
    "ds_anom['aqua_bbp_sst_anom_sign'] = xr_aqua_bbp_sst_anom_sign\n",
    "ds_anom['aqua_chl_bbp_anom_sign'] = xr_aqua_chl_bbp_anom_sign\n",
    "ds_anom['aqua_phyC_sst_anom_sign'] = xr_aqua_phyC_sst_anom_sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                     (lat: 2160, lon: 4320, time: 12)\n",
       "Coordinates:\n",
       "  * time                        (time) datetime64[ns] 2018-01-01 2018-02-01 ...\n",
       "  * lat                         (lat) float32 89.958336 89.875 89.79167 ...\n",
       "  * lon                         (lon) float32 -179.95833 -179.875 -179.79166 ...\n",
       "Data variables:\n",
       "    aqua_chl_anom               (time, lat, lon) float64 nan nan nan nan nan ...\n",
       "    aqua_phyC_anom              (time, lat, lon) float64 nan nan nan nan nan ...\n",
       "    aqua_bbp_443_anom           (time, lat, lon) float64 nan nan nan nan nan ...\n",
       "    aqua_sst_anom               (time, lat, lon) float64 nan nan nan nan nan ...\n",
       "    time_avg_aqua_chl_anom      (lat, lon) float64 nan nan nan nan nan nan ...\n",
       "    time_avg_aqua_phyC_anom     (lat, lon) float64 nan nan nan nan nan nan ...\n",
       "    time_avg_aqua_bbp_443_anom  (lat, lon) float64 nan nan nan nan nan nan ...\n",
       "    time_avg_sst_anom           (lat, lon) float64 nan nan nan nan nan nan ...\n",
       "    aqua_chl_sst_anom_sign      (lat, lon) float64 nan nan nan nan nan nan ...\n",
       "    aqua_bbp_sst_anom_sign      (lat, lon) float64 nan nan nan nan nan nan ...\n",
       "    aqua_chl_bbp_anom_sign      (lat, lon) float64 nan nan nan nan nan nan ...\n",
       "    aqua_phyC_sst_anom_sign     (lat, lon) float64 nan nan nan nan nan nan ..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_anom.to_netcdf('./xr_anom_2018.nc%s' % DT.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
