{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from IPython.core.display import HTML, display\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width: 90%}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container {width: 90%}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_secs2dt(sec):\n",
    "    \"\"\"\n",
    "    Converts seconds to python datetime object.\n",
    "    :param sec \n",
    "    :return: datetime object\n",
    "    \"\"\"\n",
    "    zd00 = datetime(2000, 1, 1)\n",
    "    zd70 = datetime(1970, 1, 1)\n",
    "    offset = (zd00 - zd70).total_seconds()\n",
    "    z = datetime.utcfromtimestamp(sec + offset)\n",
    "    return z\n",
    "\n",
    "\n",
    "def get_doy(secs):\n",
    "    \"\"\"\n",
    "    Converts seconds to fractional day of year.\n",
    "    :param secs\n",
    "    :return: fractional day of year \n",
    "    \"\"\"\n",
    "    z = convert_secs2dt(secs)\n",
    "    y = z.year\n",
    "    return (secs + (datetime(2000, 1, 1) - datetime(y, 1, 1)).total_seconds()) / 86400\n",
    "\n",
    "\n",
    "def load_format_data(filepath, minimal=True, columns=None, quantity='chl_a'):\n",
    "    \"\"\"\n",
    "    Loads chlorophyll data into a pandas dataframe,\n",
    "    formats time entries, and creates a datetime index.\n",
    "    :param filepath: string or pathlib object  \n",
    "    :param minimal: if True returns only chl_a_mean; drops the rest.\n",
    "    :return: pandas datetime indexed dataframe\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = ['time', 'nbins', 'mean', 'median', 'stdv']\n",
    "    \n",
    "    df = pd.read_csv(filepath, delim_whitespace=True, names=columns)\n",
    "    df['datetime'] = df.time.apply(convert_secs2dt)\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    if minimal:\n",
    "        df = df[['mean']]\n",
    "    df.rename(columns={'mean': '%s_mean' % quantity}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_phyto_C_stats(df_):\n",
    "    bbp_443_ = df_.bbp_443_giop_adj_mean.values.reshape(1,-1)\n",
    "    phyto_c_trace_ = intercept + bbp_443_ * slope\n",
    "    phyto_c_mean = phyto_c_trace_.mean(axis=0)\n",
    "    phyto_c_hpd = pm.hpd(phyto_c_trace_)\n",
    "    df_.insert(loc=1, column='phyto_C_2.5%', value=phyto_c_hpd[:, 0])\n",
    "    df_.insert(loc=2, column='phyto_C_97.5%', value=phyto_c_hpd[:, 1])\n",
    "    df_.insert(loc=2, column='phyto_C_mean', value=phyto_c_mean)\n",
    "    return df_\n",
    "\n",
    "def get_monthly_means(df, **kwargs):\n",
    "    \"\"\"\n",
    "    Groups data by month and compute annual cycle based on monthly means.\n",
    "    :param df: \n",
    "        datetime indexed pandas dataframe\n",
    "    :param kwargs:\n",
    "        year_start (optional): string, slice start\n",
    "        year_end (optional): string, slice end\n",
    "    :return: \n",
    "        month-indexed pandas dataframe with monthly means\n",
    "    \"\"\"\n",
    "    year_start = kwargs.pop('year_start', df.index.year[0])\n",
    "    year_end = kwargs.pop('year_end', df.index.year[-1])\n",
    "    return df.loc[str(year_start): str(year_end)].groupby(lambda x: x.month).aggregate('mean')\n",
    "\n",
    "\n",
    "def get_anomaly(df, df_ann_cycle, name='chl_a_mean', anomaly_name='anomaly'):\n",
    "    \"\"\"\n",
    "    Computes annomaly by removing monthly mean for a given month\n",
    "    :param df:\n",
    "        pandas dataframe with [name] parameter column\n",
    "    :param df_ann_cycle:\n",
    "        pandas dataframe of length 12 containing monthly means\n",
    "    :param name:\n",
    "        str, label of quantity to get anomaly from\n",
    "    :return:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    for month in df_ann_cycle.index:\n",
    "        idx = df.index.month == month\n",
    "        df.loc[idx, anomaly_name] = df.loc[idx, name] - df_ann_cycle.loc[month, name]\n",
    "\n",
    "\n",
    "def test(datadir):\n",
    "    testfile = datadir / 'ar2018.0m_AtlN55_chlor_a.txt'\n",
    "    df_test = load_format_data(testfile, minimal=False)\n",
    "    t0 = df_test.time[0]    \n",
    "    z0 = convert_secs2dt(t0)\n",
    "    zstr0 = z0.strftime('%Y%j%H%M%S')\n",
    "    try:\n",
    "        assert zstr0 + '000' == str(2002197194740000)\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        print(zstr0)\n",
    "    assert z0.year == 2002\n",
    "    doy0 = get_doy(t0)\n",
    "    assert doy0 == 196.82476851851851\n",
    "    tl = df_test.tail(1).time.values\n",
    "    zl = convert_secs2dt(tl)\n",
    "    zstrl = zl.strftime('%Y%j%H%M%S')\n",
    "    assert zstrl + '000' == str(2016321013320000)\n",
    "    assert zl.year == 2016\n",
    "    doyl = get_doy(tl)\n",
    "    assert doyl == 320.06481481481484\n",
    "    print(\"all tests passed\")\n",
    "\n",
    "def get_sensor(row, prod):\n",
    "    if np.isfinite(row[f'adj_{prod}_s'] * row[f'adj_{prod}_a']):\n",
    "        return 'both'\n",
    "    else:\n",
    "        if np.isfinite(row[f'adj_{prod}_s']):\n",
    "            return 'swf'\n",
    "        else:\n",
    "            return 'aqua'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=pathlib.Path('/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pklJar/pooled_params.pkl', 'rb') as fb:\n",
    "    pooled_params_dict = pickle.load(fb)\n",
    "slope = pooled_params_dict['slope']\n",
    "slope = slope.reshape(-1, 1)\n",
    "intercept = pooled_params_dict['intercept']\n",
    "intercept = intercept.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/sr2018.0IOPm_eqpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/sr2018.0m_eqpso_chlor_a.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/ar2018.0m_nhpso_chlor_a.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/ar2018.0m_shpso_chlor_a.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/ar2018.0IOPm_eqpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/sr2018.0m_shpso_chlor_a.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/sr2018.0m_nhpso_chlor_a.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/ar2018.0IOPm_shpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/ar2018.0IOPm_nhpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/ar2018.0m_eqpso_chlor_a.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/sr2018.0IOPm_nhpso_bbp_443_giop.txt\n",
      "/accounts/ekarakoy/DEV-ALL/State_of_the_Climate/soc2018/TIMESERIES/sr2018.0IOPm_shpso_bbp_443_giop.txt\n"
     ]
    }
   ],
   "source": [
    "for file in path.glob('*.txt'):\n",
    "    print(file.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_regionals(path_):\n",
    "    regions = ['eqpso', 'nhpso', 'shpso']\n",
    "    prods = ['chlor_a', 'bbp_443_giop']\n",
    "    sensors = ['aqua' ,'swf', 'swf_aqua']\n",
    "    dict_ = {reg: {prod: dict.fromkeys(sensors) \n",
    "               for prod in prods} \n",
    "         for reg in regions}\n",
    "    for file in path_.glob('*.txt'):\n",
    "    \n",
    "        key_reg, key_prod = None, None\n",
    "        for reg in regions:\n",
    "            if reg in file.name:\n",
    "                key_reg = reg\n",
    "                break\n",
    "        for prod in prods:\n",
    "            if prod in file.name:\n",
    "                key_prod=prod\n",
    "                break\n",
    "        sensor = 'aqua' if 'ar' in file.name else 'swf'\n",
    "        df_ = load_format_data(file, quantity=key_prod)\n",
    "        df_.rename({col: f'{sensor[0]}_{col}' for col in df_.columns},\n",
    "                   axis=1, inplace=True)\n",
    "        if sensor == 'swf':\n",
    "            df_ = df_.loc[:'2007', :]\n",
    "        dict_[key_reg][key_prod][sensor] = df_\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_df = load_regionals(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['eqpso', 'nhpso', 'shpso']\n",
    "prods = ['chlor_a', 'bbp_443_giop']\n",
    "for reg in regions:\n",
    "    for prod in prods:\n",
    "        df_aqua = dct_df[reg][prod]['aqua']\n",
    "        df_swf = dct_df[reg][prod]['swf']\n",
    "        df_all = pd.concat((df_aqua.resample('MS', loffset=pd.Timedelta(14, 'd')).first(),\n",
    "                                   df_swf.resample('MS', loffset=pd.Timedelta(14, 'd')).first()),\n",
    "                                  axis=1)\n",
    "        df_both=df_all.dropna().copy()\n",
    "        df_both.insert(0, f'{prod}_mean', df_both[[f's_{prod}_mean',\n",
    "                                                   f'a_{prod}_mean']\n",
    "                                                 ].mean(axis=1))\n",
    "        df_both.insert(1, f'aqua-{prod}_mean',\n",
    "                       df_both[f'a_{prod}_mean']- df_both[f'{prod}_mean'])\n",
    "        df_both.insert(1, f'{prod}_mean-swf',\n",
    "                       df_both[f'{prod}_mean'] - df_both[f's_{prod}_mean'])\n",
    "        df_all[f'adj_{prod}_s'] = df_all[f's_{prod}_mean'] + df_both[f'{prod}_mean-swf'].mean()\n",
    "        df_all[f'adj_{prod}_a'] = df_all[f'a_{prod}_mean'] + df_both[f'aqua-{prod}_mean'].mean()\n",
    "        df_all[f'{prod}_adj_mean'] = df_all[[f'adj_{prod}_s', f'adj_{prod}_a']].mean(axis=1)\n",
    "        df_all_sub = df_all[[f'{prod}_adj_mean']].copy()\n",
    "        if 'bbp' in prod:\n",
    "            df_all_sub = compute_phyto_C_stats(df_all_sub)\n",
    "        prod_ = 'phyto_C' if 'bbp' in prod else f'{prod}_adj'\n",
    "        prod_ann_cycle = get_monthly_means(df_all_sub[[f'{prod_}_mean']],\n",
    "                                           year_start=2003, year_end=2011)\n",
    "        get_anomaly(df_all_sub, prod_ann_cycle, name=f'{prod_}_mean',\n",
    "                   anomaly_name=f'{prod_}_anomaly')\n",
    "        df_all_sub['sensor'] = df_all.apply(get_sensor, args=(prod,), axis=1)\n",
    "        dct_df[reg][prod].update(dict(df_all=df_all_sub)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chlor_a_adj_mean</th>\n",
       "      <th>chlor_a_adj_anomaly</th>\n",
       "      <th>sensor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-11-15</th>\n",
       "      <td>0.132769</td>\n",
       "      <td>-0.010059</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-12-15</th>\n",
       "      <td>0.119800</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-15</th>\n",
       "      <td>0.097233</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-02-15</th>\n",
       "      <td>0.088248</td>\n",
       "      <td>-0.002921</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-03-15</th>\n",
       "      <td>0.095526</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>swf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            chlor_a_adj_mean  chlor_a_adj_anomaly sensor\n",
       "datetime                                                \n",
       "1997-11-15          0.132769            -0.010059    swf\n",
       "1997-12-15          0.119800             0.005873    swf\n",
       "1998-01-15          0.097233             0.001086    swf\n",
       "1998-02-15          0.088248            -0.002921    swf\n",
       "1998-03-15          0.095526             0.000255    swf"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_df[reg]['chlor_a']['df_all'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbp_443_giop_adj_mean</th>\n",
       "      <th>phyto_C_2.5%</th>\n",
       "      <th>phyto_C_mean</th>\n",
       "      <th>phyto_C_97.5%</th>\n",
       "      <th>phyto_C_anomaly</th>\n",
       "      <th>sensor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-15</th>\n",
       "      <td>0.001785</td>\n",
       "      <td>19.774038</td>\n",
       "      <td>21.448385</td>\n",
       "      <td>23.292431</td>\n",
       "      <td>0.488784</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-15</th>\n",
       "      <td>0.001882</td>\n",
       "      <td>20.838273</td>\n",
       "      <td>22.589286</td>\n",
       "      <td>24.562082</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-15</th>\n",
       "      <td>0.002096</td>\n",
       "      <td>22.999480</td>\n",
       "      <td>25.111384</td>\n",
       "      <td>27.281983</td>\n",
       "      <td>1.310841</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-15</th>\n",
       "      <td>0.002163</td>\n",
       "      <td>23.693502</td>\n",
       "      <td>25.892725</td>\n",
       "      <td>28.161080</td>\n",
       "      <td>0.978398</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-15</th>\n",
       "      <td>0.002106</td>\n",
       "      <td>23.101145</td>\n",
       "      <td>25.224415</td>\n",
       "      <td>27.411516</td>\n",
       "      <td>0.748342</td>\n",
       "      <td>aqua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bbp_443_giop_adj_mean  phyto_C_2.5%  phyto_C_mean  phyto_C_97.5%  \\\n",
       "datetime                                                                       \n",
       "2018-08-15               0.001785     19.774038     21.448385      23.292431   \n",
       "2018-09-15               0.001882     20.838273     22.589286      24.562082   \n",
       "2018-10-15               0.002096     22.999480     25.111384      27.281983   \n",
       "2018-11-15               0.002163     23.693502     25.892725      28.161080   \n",
       "2018-12-15               0.002106     23.101145     25.224415      27.411516   \n",
       "\n",
       "            phyto_C_anomaly sensor  \n",
       "datetime                            \n",
       "2018-08-15         0.488784   aqua  \n",
       "2018-09-15         0.457733   aqua  \n",
       "2018-10-15         1.310841   aqua  \n",
       "2018-11-15         0.978398   aqua  \n",
       "2018-12-15         0.748342   aqua  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_df[reg][prod]['df_all'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg in regions:\n",
    "    for prod in prods:\n",
    "        df_name = f'df_{reg}_{prod}_consolidated'\n",
    "        dct_df[reg][prod]['df_all'].to_pickle(f'../PklJar/{df_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../PklJar/dct_df.pkl', 'wb') as f:\n",
    "    pickle.dump(dct_df, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_learning]",
   "language": "python",
   "name": "conda-env-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
